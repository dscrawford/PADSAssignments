---
title: "CS6301 Assignment 1"
author: "Daniel Crawford, Abhishek, Kai"
output: html_notebook
---


```{r}
# install.packages(c('caret'))
```

```{r}
df <- read.csv('housing.csv')
df[1:10, ]
```

```{r}
require(corrplot)
require(ggplot2)
library(caret)
```
Here is a view of all the percentages of null values on each column.
```{r}
# Percentage of null values
sapply(df, function(x) sum(is.na(x))) / nrow(df)
```
It shows that the only concerning null values  is total_bedrooms. We can eliminate these values.
```{r}
# Remove unwanted null values
df <- na.omit(df)
```

Now view histograms of each of the variables (Aside from the categorical variable 'ocean proximity')
```{r, message=FALSE, results='hide'}
layout(matrix(1:9, 3, 3, byrow=TRUE))
lapply(colnames(df[-which(colnames(df) == 'ocean_proximity')]), 
       FUN=function(x) hist(as.vector(df[[x]]),
                            main=paste(x),
                            xlab=x,
                            breaks=50
                            )
       )
```
Above is the histograms of all the variables available to us. We can see that most of these variables are normally distributed, but some have discrepancies. 
Housing median age seems to have a big jump in frequency of age at specific points in time. It is likely that something influenced more housing construction in these time periods, so it is an odd variable. Lastly, it looks like they capped the age at about 52 years old, likely because the data was not tracked before a certain time well.
Longitude and Latitude being used is expected to be weird since they are location points. We can see though that the most densely populated areas will dominate our data set.
Our target, median house value, has a cap similar to housing median age. Because of this, these outliers can hurt our results pretty badly on a linear fit.

We want to see how useful the categorical variable 'Ocean Proximity' is, so we are going to transform it into dummy variables.
```{r}
# One hot encode categorical variables
dummy <- dummyVars(" ~ .", data=df)
df <- data.frame(predict(dummy, newdata=df))
df[1:3, 10:ncol(df)]
```

Show a correlation plot for all of the variables (using the dummy variables for categoricals)
```{r}
M <- cor(df)
corplot <- corrplot(M, method="circle", tl.cex=0.5)
cormat <- as.data.frame(corrplot(M,method = "number", tl.cex=0.5, cl.cex = 0.5, number.cex= 0.6))
```
Shown in these plots, we can see that many of these values are weekly correlated with the median house value, but we still see some linearity. Likely we will need to introduce a strategy to overcome these weak correlations.

Let us serach for the variables with correlation above 0.5 to median_house value.
```{r}
row.names(cormat)[abs(cormat$median_house_value) > 0.5]
```
```{r}
#Plots to check linearity of each var

plot_line <- function (x) {
  plot(as.vector(df[[x]]),
       as.vector(df$median_house_value),
       main=paste(x),
       xlab=x,
       ylab='median_house_value')
  abline(lm(df$median_house_value ~ df[[x]]), lwd=3, col="red")
}

layout(matrix(c(1:col(df)), 7, 2, byrow=TRUE), widths=rep(1, ncol(df)), heights=rep(1.5, ncol(df)))
lapply(colnames(df[-which(colnames(df) == 'median_house_value')]), 
       FUN=plot_line
) 
```
```{r}
plot(df$longitude, df$latitude)
```



